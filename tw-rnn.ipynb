{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to demonstrate the use of RNNs using generated data. By generating data ourselves, we have more control over what we train and test the model on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import randint, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Types of Cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cats are lazy. They do only one thing every hour. There exists several types of cats. \n",
    "\n",
    "Testing that RNN's are capable of performing sequence prediction over different kinds of sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Most cats perform one of four actions\n",
    "EAT = 0\n",
    "NAP = 1\n",
    "SCRATCH = 2 \n",
    "BEAT_UP_STINKY_DOG = 3\n",
    "\n",
    "NUM_POSSIBLE_NORMAL_ACTIONS = 4\n",
    "NUM_POSSIBLE_ACTIONS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_action_round_robin(current_action): \n",
    "    return (current_action + 1) % NUM_POSSIBLE_NORMAL_ACTIONS\n",
    "\n",
    "def random_action(): \n",
    "    return randint(0, NUM_POSSIBLE_NORMAL_ACTIONS - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictable Cat behaves in a round robin fashion. Robin... how ironic. \n",
    "def predictable_cat():\n",
    "    action = random_action()\n",
    "    while True: \n",
    "        yield action\n",
    "        action = next_action_round_robin(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OCD Cat does everything in threes, no more, no less...\n",
    "def ocd_cat(): \n",
    "    action = random_action()\n",
    "    while True: \n",
    "        yield action\n",
    "        yield action\n",
    "        yield action\n",
    "        action = next_action_round_robin(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unpredictable cat performs a random action sometimes, and resumes the sequence from there\n",
    "# This adds some noise to our data, the RNN seems robust to that based on accuracy score. \n",
    "# On hindsight, should have tagged the cats to check which ones get misclassified.\n",
    "def unpredictable_cat():\n",
    "    action = random_action()\n",
    "    while True:\n",
    "        action = next_action_round_robin(action) if random() < 0.5 else random_action()\n",
    "        yield action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Smelly Cat raids the dumpster every other action\n",
    "RAID_DUMPSTER = 4\n",
    "\n",
    "def smelly_cat():\n",
    "    action = random_action()\n",
    "    while True:\n",
    "        yield action\n",
    "        yield RAID_DUMPSTER\n",
    "        action = next_action_round_robin(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 3, 4, 0, 4, 1, 4, 2, 4, 3, 4, 0, 4, 1, 4, 2, 4, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at Smelly Cat's day\n",
    "cat = smelly_cat()\n",
    "smelly_actions = [next(cat) for i in range(0,20)]\n",
    "print(smelly_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cat_randomizer(with_noise = False):\n",
    "    cat_gens = [predictable_cat, ocd_cat, smelly_cat]\n",
    "    if with_noise:\n",
    "        cat_gens += [unpredictable_cat]\n",
    "\n",
    "    while True:\n",
    "        yield cat_gens[randint(0, len(cat_gens) - 1)]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def actions_for(cat, num_actions):\n",
    "    return [next(cat) for i in range(0, num_actions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use one-hot encoding to represent actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(labels, num_classes): \n",
    "    return [[1 if i == label else 0 for i in range(0, num_classes)] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(smelly_actions, NUM_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for some kitty action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bring_me_some_cats(cat_count):\n",
    "    rand_cat = cat_randomizer(True)\n",
    "    for i in range(0, cat_count):\n",
    "        yield next(rand_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_actions = 51\n",
    "num_cats = 500\n",
    "kitties_actions = [one_hot(actions_for(cat, num_actions), NUM_POSSIBLE_ACTIONS) for cat in bring_me_some_cats(num_cats)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splice out the last action, this is the \"label\" that we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = kitties_initial_actions = [k[:num_actions - 1] for k in kitties_actions]\n",
    "y = kitties_last_action = [k[-1] for k in kitties_actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(smelly_actions, NUM_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for some kitty action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bring_me_some_cats(cat_count):\n",
    "    rand_cat = cat_randomizer()\n",
    "    for i in range(0, cat_count):\n",
    "        yield next(rand_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_actions = 51\n",
    "num_cats = 500\n",
    "kitties_actions = [one_hot(actions_for(cat, num_actions), NUM_POSSIBLE_ACTIONS) for cat in bring_me_some_cats(num_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_kitty_actions(actions): #punintended\n",
    "    actions_decoded = np.argmax(actions, axis=2)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.imshow(actions_decoded, interpolation='nearest', cmap=plt.cm.magma)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAFkCAYAAACaWsQxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVlt/f/SAJMKxgugoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116cdf908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_kitty_actions(kitties_actions[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splice out the last action, this is the \"label\" that we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = kitties_initial_actions = [k[:num_actions - 1] for k in kitties_actions]\n",
    "y = kitties_last_action = [k[-1] for k in kitties_actions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into a training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 120\n",
    "HIDDEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN, input_shape=[50, 5]))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "375/375 [==============================] - 0s - loss: 1.8222 - acc: 0.1840     \n",
      "Epoch 2/120\n",
      "375/375 [==============================] - 0s - loss: 1.7882 - acc: 0.1840     \n",
      "Epoch 3/120\n",
      "375/375 [==============================] - 0s - loss: 1.7564 - acc: 0.1840     \n",
      "Epoch 4/120\n",
      "375/375 [==============================] - 0s - loss: 1.7268 - acc: 0.2453     \n",
      "Epoch 5/120\n",
      "375/375 [==============================] - 0s - loss: 1.6984 - acc: 0.2587     \n",
      "Epoch 6/120\n",
      "375/375 [==============================] - 0s - loss: 1.6721 - acc: 0.2587     \n",
      "Epoch 7/120\n",
      "375/375 [==============================] - 0s - loss: 1.6472 - acc: 0.2587     \n",
      "Epoch 8/120\n",
      "375/375 [==============================] - 0s - loss: 1.6236 - acc: 0.2587     \n",
      "Epoch 9/120\n",
      "375/375 [==============================] - 0s - loss: 1.6013 - acc: 0.2773     \n",
      "Epoch 10/120\n",
      "375/375 [==============================] - 0s - loss: 1.5799 - acc: 0.3387     \n",
      "Epoch 11/120\n",
      "375/375 [==============================] - 0s - loss: 1.5587 - acc: 0.3387     \n",
      "Epoch 12/120\n",
      "375/375 [==============================] - 0s - loss: 1.5382 - acc: 0.3387     \n",
      "Epoch 13/120\n",
      "375/375 [==============================] - 0s - loss: 1.5180 - acc: 0.3387     \n",
      "Epoch 14/120\n",
      "375/375 [==============================] - 0s - loss: 1.4979 - acc: 0.3387     \n",
      "Epoch 15/120\n",
      "375/375 [==============================] - 0s - loss: 1.4784 - acc: 0.3387     \n",
      "Epoch 16/120\n",
      "375/375 [==============================] - 0s - loss: 1.4587 - acc: 0.4320     \n",
      "Epoch 17/120\n",
      "375/375 [==============================] - 0s - loss: 1.4403 - acc: 0.4320     \n",
      "Epoch 18/120\n",
      "375/375 [==============================] - 0s - loss: 1.4207 - acc: 0.4320     \n",
      "Epoch 19/120\n",
      "375/375 [==============================] - 0s - loss: 1.4010 - acc: 0.4320     \n",
      "Epoch 20/120\n",
      "375/375 [==============================] - 0s - loss: 1.3808 - acc: 0.4320     \n",
      "Epoch 21/120\n",
      "375/375 [==============================] - 0s - loss: 1.3607 - acc: 0.4320     \n",
      "Epoch 22/120\n",
      "375/375 [==============================] - 0s - loss: 1.3401 - acc: 0.5227     \n",
      "Epoch 23/120\n",
      "375/375 [==============================] - 0s - loss: 1.3201 - acc: 0.5227     \n",
      "Epoch 24/120\n",
      "375/375 [==============================] - 0s - loss: 1.2978 - acc: 0.5227     \n",
      "Epoch 25/120\n",
      "375/375 [==============================] - 0s - loss: 1.2759 - acc: 0.5227     \n",
      "Epoch 26/120\n",
      "375/375 [==============================] - 0s - loss: 1.2542 - acc: 0.5227     \n",
      "Epoch 27/120\n",
      "375/375 [==============================] - 0s - loss: 1.2317 - acc: 0.5227     \n",
      "Epoch 28/120\n",
      "375/375 [==============================] - 0s - loss: 1.2091 - acc: 0.5227     \n",
      "Epoch 29/120\n",
      "375/375 [==============================] - 0s - loss: 1.1874 - acc: 0.5227     \n",
      "Epoch 30/120\n",
      "375/375 [==============================] - 0s - loss: 1.1644 - acc: 0.5227     \n",
      "Epoch 31/120\n",
      "375/375 [==============================] - 0s - loss: 1.1421 - acc: 0.5227     \n",
      "Epoch 32/120\n",
      "375/375 [==============================] - 0s - loss: 1.1217 - acc: 0.5227     \n",
      "Epoch 33/120\n",
      "375/375 [==============================] - 0s - loss: 1.0988 - acc: 0.5653     \n",
      "Epoch 34/120\n",
      "375/375 [==============================] - 0s - loss: 1.0778 - acc: 0.5920     \n",
      "Epoch 35/120\n",
      "375/375 [==============================] - 0s - loss: 1.0582 - acc: 0.5920     \n",
      "Epoch 36/120\n",
      "375/375 [==============================] - 0s - loss: 1.0394 - acc: 0.5920     \n",
      "Epoch 37/120\n",
      "375/375 [==============================] - 0s - loss: 1.0212 - acc: 0.5920     \n",
      "Epoch 38/120\n",
      "375/375 [==============================] - 0s - loss: 1.0040 - acc: 0.6293     \n",
      "Epoch 39/120\n",
      "375/375 [==============================] - 0s - loss: 0.9869 - acc: 0.6640     \n",
      "Epoch 40/120\n",
      "375/375 [==============================] - 0s - loss: 0.9701 - acc: 0.6640     \n",
      "Epoch 41/120\n",
      "375/375 [==============================] - 0s - loss: 0.9538 - acc: 0.7200     \n",
      "Epoch 42/120\n",
      "375/375 [==============================] - 0s - loss: 0.9382 - acc: 0.8027     \n",
      "Epoch 43/120\n",
      "375/375 [==============================] - 0s - loss: 0.9225 - acc: 0.8320     \n",
      "Epoch 44/120\n",
      "375/375 [==============================] - 0s - loss: 0.9069 - acc: 0.8320     \n",
      "Epoch 45/120\n",
      "375/375 [==============================] - 0s - loss: 0.8922 - acc: 0.8320     \n",
      "Epoch 46/120\n",
      "375/375 [==============================] - 0s - loss: 0.8777 - acc: 0.8320     \n",
      "Epoch 47/120\n",
      "375/375 [==============================] - 0s - loss: 0.8631 - acc: 0.8320     \n",
      "Epoch 48/120\n",
      "375/375 [==============================] - 0s - loss: 0.8487 - acc: 0.8320     \n",
      "Epoch 49/120\n",
      "375/375 [==============================] - 0s - loss: 0.8348 - acc: 0.8320     \n",
      "Epoch 50/120\n",
      "375/375 [==============================] - 0s - loss: 0.8212 - acc: 0.8827     \n",
      "Epoch 51/120\n",
      "375/375 [==============================] - 0s - loss: 0.8083 - acc: 0.9280     \n",
      "Epoch 52/120\n",
      "375/375 [==============================] - 0s - loss: 0.7948 - acc: 0.9280     \n",
      "Epoch 53/120\n",
      "375/375 [==============================] - 0s - loss: 0.7818 - acc: 0.9280     \n",
      "Epoch 54/120\n",
      "375/375 [==============================] - 0s - loss: 0.7683 - acc: 0.9280     \n",
      "Epoch 55/120\n",
      "375/375 [==============================] - 0s - loss: 0.7535 - acc: 0.9280     \n",
      "Epoch 56/120\n",
      "375/375 [==============================] - 0s - loss: 0.7382 - acc: 0.9280     \n",
      "Epoch 57/120\n",
      "375/375 [==============================] - 0s - loss: 0.7188 - acc: 0.9280     \n",
      "Epoch 58/120\n",
      "375/375 [==============================] - 0s - loss: 0.6995 - acc: 0.9280     \n",
      "Epoch 59/120\n",
      "375/375 [==============================] - 0s - loss: 0.6822 - acc: 0.9280     \n",
      "Epoch 60/120\n",
      "375/375 [==============================] - 0s - loss: 0.6676 - acc: 0.9280     \n",
      "Epoch 61/120\n",
      "375/375 [==============================] - 0s - loss: 0.6545 - acc: 0.9280     \n",
      "Epoch 62/120\n",
      "375/375 [==============================] - 0s - loss: 0.6408 - acc: 0.9280     \n",
      "Epoch 63/120\n",
      "375/375 [==============================] - 0s - loss: 0.6283 - acc: 0.9280     \n",
      "Epoch 64/120\n",
      "375/375 [==============================] - 0s - loss: 0.6150 - acc: 0.9280     \n",
      "Epoch 65/120\n",
      "375/375 [==============================] - 0s - loss: 0.6026 - acc: 0.9280     \n",
      "Epoch 66/120\n",
      "375/375 [==============================] - 0s - loss: 0.5905 - acc: 0.9280     \n",
      "Epoch 67/120\n",
      "375/375 [==============================] - 0s - loss: 0.5787 - acc: 0.9280     \n",
      "Epoch 68/120\n",
      "375/375 [==============================] - 0s - loss: 0.5673 - acc: 0.9280     \n",
      "Epoch 69/120\n",
      "375/375 [==============================] - 0s - loss: 0.5564 - acc: 0.9280     \n",
      "Epoch 70/120\n",
      "375/375 [==============================] - 0s - loss: 0.5456 - acc: 0.9280     \n",
      "Epoch 71/120\n",
      "375/375 [==============================] - 0s - loss: 0.5349 - acc: 0.9280     \n",
      "Epoch 72/120\n",
      "375/375 [==============================] - 0s - loss: 0.5247 - acc: 0.9280     \n",
      "Epoch 73/120\n",
      "375/375 [==============================] - 0s - loss: 0.5146 - acc: 1.0000     \n",
      "Epoch 74/120\n",
      "375/375 [==============================] - 0s - loss: 0.5050 - acc: 1.0000     \n",
      "Epoch 75/120\n",
      "375/375 [==============================] - 0s - loss: 0.4953 - acc: 1.0000     \n",
      "Epoch 76/120\n",
      "375/375 [==============================] - 0s - loss: 0.4858 - acc: 1.0000     \n",
      "Epoch 77/120\n",
      "375/375 [==============================] - 0s - loss: 0.4763 - acc: 1.0000     \n",
      "Epoch 78/120\n",
      "375/375 [==============================] - 0s - loss: 0.4670 - acc: 1.0000     \n",
      "Epoch 79/120\n",
      "375/375 [==============================] - 0s - loss: 0.4581 - acc: 1.0000     \n",
      "Epoch 80/120\n",
      "375/375 [==============================] - 0s - loss: 0.4492 - acc: 1.0000     \n",
      "Epoch 81/120\n",
      "375/375 [==============================] - 0s - loss: 0.4405 - acc: 1.0000     \n",
      "Epoch 82/120\n",
      "375/375 [==============================] - 0s - loss: 0.4319 - acc: 1.0000     \n",
      "Epoch 83/120\n",
      "375/375 [==============================] - 0s - loss: 0.4233 - acc: 1.0000     \n",
      "Epoch 84/120\n",
      "375/375 [==============================] - 0s - loss: 0.4150 - acc: 1.0000     \n",
      "Epoch 85/120\n",
      "375/375 [==============================] - 0s - loss: 0.4065 - acc: 1.0000     \n",
      "Epoch 86/120\n",
      "375/375 [==============================] - 0s - loss: 0.3983 - acc: 1.0000     \n",
      "Epoch 87/120\n",
      "375/375 [==============================] - 0s - loss: 0.3901 - acc: 1.0000     \n",
      "Epoch 88/120\n",
      "375/375 [==============================] - 0s - loss: 0.3822 - acc: 1.0000     \n",
      "Epoch 89/120\n",
      "375/375 [==============================] - 0s - loss: 0.3743 - acc: 1.0000     \n",
      "Epoch 90/120\n",
      "375/375 [==============================] - 0s - loss: 0.3667 - acc: 1.0000     \n",
      "Epoch 91/120\n",
      "375/375 [==============================] - 0s - loss: 0.3591 - acc: 1.0000     \n",
      "Epoch 92/120\n",
      "375/375 [==============================] - 0s - loss: 0.3520 - acc: 1.0000     \n",
      "Epoch 93/120\n",
      "375/375 [==============================] - 0s - loss: 0.3448 - acc: 1.0000     \n",
      "Epoch 94/120\n",
      "375/375 [==============================] - 0s - loss: 0.3377 - acc: 1.0000     \n",
      "Epoch 95/120\n",
      "375/375 [==============================] - 0s - loss: 0.3310 - acc: 1.0000     \n",
      "Epoch 96/120\n",
      "375/375 [==============================] - 0s - loss: 0.3243 - acc: 1.0000     \n",
      "Epoch 97/120\n",
      "375/375 [==============================] - 0s - loss: 0.3177 - acc: 1.0000     \n",
      "Epoch 98/120\n",
      "375/375 [==============================] - 0s - loss: 0.3114 - acc: 1.0000     \n",
      "Epoch 99/120\n",
      "375/375 [==============================] - 0s - loss: 0.3051 - acc: 1.0000     \n",
      "Epoch 100/120\n",
      "375/375 [==============================] - 0s - loss: 0.2990 - acc: 1.0000     \n",
      "Epoch 101/120\n",
      "375/375 [==============================] - 0s - loss: 0.2930 - acc: 1.0000     \n",
      "Epoch 102/120\n",
      "375/375 [==============================] - 0s - loss: 0.2871 - acc: 1.0000     \n",
      "Epoch 103/120\n",
      "375/375 [==============================] - 0s - loss: 0.2816 - acc: 1.0000     \n",
      "Epoch 104/120\n",
      "375/375 [==============================] - 0s - loss: 0.2776 - acc: 1.0000     \n",
      "Epoch 105/120\n",
      "375/375 [==============================] - 0s - loss: 0.2742 - acc: 1.0000     \n",
      "Epoch 106/120\n",
      "375/375 [==============================] - 0s - loss: 0.2681 - acc: 1.0000     \n",
      "Epoch 107/120\n",
      "375/375 [==============================] - 0s - loss: 0.2635 - acc: 1.0000     \n",
      "Epoch 108/120\n",
      "375/375 [==============================] - 0s - loss: 0.2590 - acc: 1.0000     \n",
      "Epoch 109/120\n",
      "375/375 [==============================] - 0s - loss: 0.2533 - acc: 1.0000     \n",
      "Epoch 110/120\n",
      "375/375 [==============================] - 0s - loss: 0.2498 - acc: 1.0000     \n",
      "Epoch 111/120\n",
      "375/375 [==============================] - 0s - loss: 0.2444 - acc: 1.0000     \n",
      "Epoch 112/120\n",
      "375/375 [==============================] - 0s - loss: 0.2397 - acc: 1.0000     \n",
      "Epoch 113/120\n",
      "375/375 [==============================] - 0s - loss: 0.2352 - acc: 1.0000     \n",
      "Epoch 114/120\n",
      "375/375 [==============================] - 0s - loss: 0.2308 - acc: 1.0000     \n",
      "Epoch 115/120\n",
      "375/375 [==============================] - 0s - loss: 0.2268 - acc: 1.0000     \n",
      "Epoch 116/120\n",
      "375/375 [==============================] - 0s - loss: 0.2224 - acc: 1.0000     \n",
      "Epoch 117/120\n",
      "375/375 [==============================] - 0s - loss: 0.2187 - acc: 1.0000     \n",
      "Epoch 118/120\n",
      "375/375 [==============================] - 0s - loss: 0.2147 - acc: 1.0000     \n",
      "Epoch 119/120\n",
      "375/375 [==============================] - 0s - loss: 0.2110 - acc: 1.0000     \n",
      "Epoch 120/120\n",
      "375/375 [==============================] - 0s - loss: 0.2071 - acc: 1.0000     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116cdf2e8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_from_vector(v): \n",
    "    return np.argmax(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03579259,  0.85906619,  0.09336755,  0.00305004,  0.00872359],\n",
       "       [ 0.06197611,  0.00387427,  0.0711435 ,  0.82790053,  0.0351056 ],\n",
       "       [ 0.03579259,  0.85906619,  0.09336755,  0.00305004,  0.00872359]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual_labels = [label_from_vector(yt) for yt in y_test]\n",
    "predicted_labels = [label_from_vector(yp) for yp in y_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35,  0,  0,  0],\n",
       "       [ 0, 24,  0,  0],\n",
       "       [ 0,  0, 26,  0],\n",
       "       [ 0,  0,  0, 40]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(actual_labels, predicted_labels, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sometimes, cats' behaviors depend on the weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this section is (still unrealized) two-fold. \n",
    "1) Show the effectiveness on LSTMs on tasks that RNN's cannot handle (long sequences where associations are separated far in time),\n",
    "2) Incorporate an input (weather) at each time step and in combination with past history, make a prediction.\n",
    "\n",
    "Note: I have tried varying the data some ways, but have not yet found a case where LSTMs outperform simple RNN's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUNNY = 0\n",
    "RAINY = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sunny_rainy_sunny(rainy_period_start, rainy_duration):\n",
    "    for i in range(0, rainy_period_start):\n",
    "        yield SUNNY\n",
    "    for i in range(0, rainy_duration):\n",
    "        yield RAINY\n",
    "    while True: \n",
    "        yield SUNNY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rain_cat(weather):\n",
    "    action = random_action()\n",
    "    while True:\n",
    "        if next(weather) == RAINY: \n",
    "            yield NAP\n",
    "        else:\n",
    "            yield action\n",
    "            action = next_action_round_robin(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def random_weather_sequence():\n",
    "    rain_start = randint(40, 45)\n",
    "    srs = sunny_rainy_sunny(rain_start, num_actions - rain_start - 1)\n",
    "    return srs\n",
    "\n",
    "rain_cats = [rain_cat(random_weather_sequence()) for i in range(250)]\n",
    "rain_cats_actions = [one_hot(actions_for(cat, num_actions), NUM_POSSIBLE_NORMAL_ACTIONS) for cat in rain_cats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAFkCAYAAACaWsQxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVlpOUmZmVlp/X+tWW6VbDhdHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119d3be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_kitty_actions(rain_cats_actions[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = rain_cats_initial_actions = [k[:num_actions - 1] for k in rain_cats_actions]\n",
    "y = rain_cats_last_action = [k[-1] for k in rain_cats_actions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into a training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters & Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 250\n",
    "HIDDEN = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(type):\n",
    "    model = Sequential()\n",
    "    input_shape = [num_actions - 1, NUM_POSSIBLE_NORMAL_ACTIONS]\n",
    "    \n",
    "    if type == \"simple\":\n",
    "        model.add(SimpleRNN(HIDDEN, input_shape=input_shape, activation=\"relu\", recurrent_initializer=\"random_uniform\"))\n",
    "    elif type == \"LSTM\":\n",
    "        model.add(LSTM(HIDDEN, input_shape=input_shape, activation=\"relu\", recurrent_activation=\"sigmoid\", recurrent_initializer=\"random_uniform\"))\n",
    "    elif type == \"LSTM64\":\n",
    "        model.add(LSTM(64, input_dim=64, input_length=10, return_sequences=True))\n",
    "    else:\n",
    "        raise Error(\"invalid layer type\")\n",
    "        \n",
    "    opt = optimizers.Adam(clipvalue=1.0, lr=0.001, decay=0.02) \n",
    "    model.add(Dense(NUM_POSSIBLE_NORMAL_ACTIONS, activation='softmax'))\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    y_predicted = model.predict(X_test)\n",
    "    actual_labels = [np.argmax(yt) for yt in y_test]\n",
    "    predicted_labels = [np.argmax(yp) for yp in y_predicted]\n",
    "    conf_matrix = confusion_matrix(actual_labels, predicted_labels)\n",
    "    score = f1_score(actual_labels, predicted_labels, average='macro')\n",
    "    print(conf_matrix)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_eval(type):\n",
    "    K.backend.clear_session()  # learning rate is practically zero if re-running LSTM without this\n",
    "    print(\"Evaluating {}\".format(type))\n",
    "    model = build_model(type)\n",
    "    train(model, X_train, y_train)\n",
    "    evaluate(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating simple\n",
      "Epoch 1/250\n",
      "187/187 [==============================] - 0s - loss: 1.4054 - acc: 0.2727     \n",
      "Epoch 2/250\n",
      "187/187 [==============================] - 0s - loss: 1.4010 - acc: 0.2727     \n",
      "Epoch 3/250\n",
      "187/187 [==============================] - 0s - loss: 1.3968 - acc: 0.2727     \n",
      "Epoch 4/250\n",
      "187/187 [==============================] - 0s - loss: 1.3940 - acc: 0.2727     \n",
      "Epoch 5/250\n",
      "187/187 [==============================] - 0s - loss: 1.3903 - acc: 0.2727     \n",
      "Epoch 6/250\n",
      "187/187 [==============================] - 0s - loss: 1.3883 - acc: 0.2727     \n",
      "Epoch 7/250\n",
      "187/187 [==============================] - 0s - loss: 1.3864 - acc: 0.2727     \n",
      "Epoch 8/250\n",
      "187/187 [==============================] - 0s - loss: 1.3841 - acc: 0.2727     \n",
      "Epoch 9/250\n",
      "187/187 [==============================] - 0s - loss: 1.3825 - acc: 0.2727     \n",
      "Epoch 10/250\n",
      "187/187 [==============================] - 0s - loss: 1.3811 - acc: 0.2727     \n",
      "Epoch 11/250\n",
      "187/187 [==============================] - 0s - loss: 1.3797 - acc: 0.2727     \n",
      "Epoch 12/250\n",
      "187/187 [==============================] - 0s - loss: 1.3787 - acc: 0.2727     \n",
      "Epoch 13/250\n",
      "187/187 [==============================] - 0s - loss: 1.3776 - acc: 0.2727     \n",
      "Epoch 14/250\n",
      "187/187 [==============================] - 0s - loss: 1.3767 - acc: 0.2727     \n",
      "Epoch 15/250\n",
      "187/187 [==============================] - 0s - loss: 1.3759 - acc: 0.2727     \n",
      "Epoch 16/250\n",
      "187/187 [==============================] - 0s - loss: 1.3755 - acc: 0.2727     \n",
      "Epoch 17/250\n",
      "187/187 [==============================] - 0s - loss: 1.3749 - acc: 0.2727     \n",
      "Epoch 18/250\n",
      "187/187 [==============================] - 0s - loss: 1.3742 - acc: 0.2727     \n",
      "Epoch 19/250\n",
      "187/187 [==============================] - 0s - loss: 1.3740 - acc: 0.2727     \n",
      "Epoch 20/250\n",
      "187/187 [==============================] - 0s - loss: 1.3734 - acc: 0.2727     \n",
      "Epoch 21/250\n",
      "187/187 [==============================] - 0s - loss: 1.3732 - acc: 0.2727     \n",
      "Epoch 22/250\n",
      "187/187 [==============================] - 0s - loss: 1.3729 - acc: 0.2727     \n",
      "Epoch 23/250\n",
      "187/187 [==============================] - 0s - loss: 1.3727 - acc: 0.2727     \n",
      "Epoch 24/250\n",
      "187/187 [==============================] - 0s - loss: 1.3724 - acc: 0.2727     \n",
      "Epoch 25/250\n",
      "187/187 [==============================] - 0s - loss: 1.3722 - acc: 0.2727     \n",
      "Epoch 26/250\n",
      "187/187 [==============================] - 0s - loss: 1.3721 - acc: 0.2727     \n",
      "Epoch 27/250\n",
      "187/187 [==============================] - 0s - loss: 1.3719 - acc: 0.2727     \n",
      "Epoch 28/250\n",
      "187/187 [==============================] - 0s - loss: 1.3717 - acc: 0.2727     \n",
      "Epoch 29/250\n",
      "187/187 [==============================] - 0s - loss: 1.3717 - acc: 0.2727     \n",
      "Epoch 30/250\n",
      "187/187 [==============================] - 0s - loss: 1.3715 - acc: 0.2727     \n",
      "Epoch 31/250\n",
      "187/187 [==============================] - 0s - loss: 1.3715 - acc: 0.2727     \n",
      "Epoch 32/250\n",
      "187/187 [==============================] - 0s - loss: 1.3714 - acc: 0.2727     \n",
      "Epoch 33/250\n",
      "187/187 [==============================] - 0s - loss: 1.3713 - acc: 0.2727     \n",
      "Epoch 34/250\n",
      "187/187 [==============================] - 0s - loss: 1.3712 - acc: 0.2727     \n",
      "Epoch 35/250\n",
      "187/187 [==============================] - 0s - loss: 1.3712 - acc: 0.2727     \n",
      "Epoch 36/250\n",
      "187/187 [==============================] - 0s - loss: 1.3712 - acc: 0.2727     \n",
      "Epoch 37/250\n",
      "187/187 [==============================] - 0s - loss: 1.3712 - acc: 0.2727     \n",
      "Epoch 38/250\n",
      "187/187 [==============================] - 0s - loss: 1.3710 - acc: 0.2727     \n",
      "Epoch 39/250\n",
      "187/187 [==============================] - 0s - loss: 1.3710 - acc: 0.2620     \n",
      "Epoch 40/250\n",
      "187/187 [==============================] - 0s - loss: 1.3710 - acc: 0.2781     \n",
      "Epoch 41/250\n",
      "187/187 [==============================] - 0s - loss: 1.3710 - acc: 0.2781     \n",
      "Epoch 42/250\n",
      "187/187 [==============================] - 0s - loss: 1.3710 - acc: 0.2781     \n",
      "Epoch 43/250\n",
      "187/187 [==============================] - 0s - loss: 1.3709 - acc: 0.2781     \n",
      "Epoch 44/250\n",
      "187/187 [==============================] - 0s - loss: 1.3709 - acc: 0.2781     \n",
      "Epoch 45/250\n",
      "187/187 [==============================] - 0s - loss: 1.3709 - acc: 0.2781     \n",
      "Epoch 46/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 47/250\n",
      "187/187 [==============================] - 0s - loss: 1.3709 - acc: 0.2781     \n",
      "Epoch 48/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 49/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 50/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 51/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 52/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 53/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 54/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 55/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 56/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 57/250\n",
      "187/187 [==============================] - 0s - loss: 1.3709 - acc: 0.2781     \n",
      "Epoch 58/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 59/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 60/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 61/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 62/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 63/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 64/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 65/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 66/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 67/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 68/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 69/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 70/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 71/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 72/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 73/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 74/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 75/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 76/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 77/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 78/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 79/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 80/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 81/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 82/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 83/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 84/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 85/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 86/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 87/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 88/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 89/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 90/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 91/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 92/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 93/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 94/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 95/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 96/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 97/250\n",
      "187/187 [==============================] - 0s - loss: 1.3708 - acc: 0.2781     \n",
      "Epoch 98/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 99/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 100/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 101/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 102/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 103/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 104/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 105/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 106/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 107/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 108/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 109/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 110/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 111/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 112/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 113/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 114/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 115/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 116/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 117/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 118/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 119/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 120/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 121/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 122/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 123/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 124/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 125/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 126/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 127/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 128/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 129/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 130/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 131/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 132/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 133/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 134/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 135/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 136/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 137/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 138/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 139/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 140/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 141/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 142/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 143/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 144/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 145/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 146/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 147/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 148/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 149/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 150/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 151/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 152/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 153/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 154/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 155/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 156/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 157/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 158/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 159/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 160/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 161/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 162/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 163/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 164/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 165/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 166/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 167/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 168/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 169/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 170/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 171/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 172/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 173/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 174/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 175/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 176/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 177/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 178/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 179/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 180/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 181/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 182/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 183/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 184/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 185/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 186/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 187/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 188/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 189/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 190/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 191/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 192/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 193/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 194/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 195/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 196/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 197/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 198/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 199/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 200/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 201/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 202/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 203/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 204/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 205/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 206/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 207/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 208/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 209/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 210/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 211/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 212/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 213/250\n",
      "187/187 [==============================] - 0s - loss: 1.3707 - acc: 0.2781     \n",
      "Epoch 214/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 215/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 216/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 217/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 218/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 219/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 220/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 221/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 222/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 223/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 224/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 225/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 226/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 227/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 228/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 229/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 230/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 231/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 232/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 233/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 234/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 235/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 236/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 237/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 238/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 239/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 240/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 241/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 242/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 243/250\n",
      "187/187 [==============================] - 0s - loss: 1.3706 - acc: 0.2781     \n",
      "Epoch 244/250\n",
      "187/187 [==============================] - 0s - loss: 1.3705 - acc: 0.2781     \n",
      "Epoch 245/250\n",
      "187/187 [==============================] - 0s - loss: 1.3705 - acc: 0.2781     \n",
      "Epoch 246/250\n",
      "187/187 [==============================] - 0s - loss: 1.3705 - acc: 0.2781     \n",
      "Epoch 247/250\n",
      "187/187 [==============================] - 0s - loss: 1.3705 - acc: 0.2781     \n",
      "Epoch 248/250\n",
      "187/187 [==============================] - 0s - loss: 1.3705 - acc: 0.2781     \n",
      "Epoch 249/250\n",
      "187/187 [==============================] - 0s - loss: 1.3705 - acc: 0.2781     \n",
      "Epoch 250/250\n",
      "187/187 [==============================] - 0s - loss: 1.3705 - acc: 0.2781     \n",
      "[[ 0  0 21  0]\n",
      " [ 0  0 15  0]\n",
      " [ 0  0 14  0]\n",
      " [ 0  0 13  0]]\n",
      "0.0909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/prog/data-science/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_and_eval(\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LSTM\n",
      "Epoch 1/250\n",
      "187/187 [==============================] - 1s - loss: 1.3937 - acc: 0.1551     \n",
      "Epoch 2/250\n",
      "187/187 [==============================] - 0s - loss: 1.3899 - acc: 0.3048     \n",
      "Epoch 3/250\n",
      "187/187 [==============================] - 0s - loss: 1.3871 - acc: 0.3155     \n",
      "Epoch 4/250\n",
      "187/187 [==============================] - 0s - loss: 1.3843 - acc: 0.3369     \n",
      "Epoch 5/250\n",
      "187/187 [==============================] - 0s - loss: 1.3825 - acc: 0.3155     \n",
      "Epoch 6/250\n",
      "187/187 [==============================] - 0s - loss: 1.3804 - acc: 0.3316     \n",
      "Epoch 7/250\n",
      "187/187 [==============================] - 0s - loss: 1.3790 - acc: 0.2727     \n",
      "Epoch 8/250\n",
      "187/187 [==============================] - 0s - loss: 1.3773 - acc: 0.2727     \n",
      "Epoch 9/250\n",
      "187/187 [==============================] - 0s - loss: 1.3762 - acc: 0.2727     \n",
      "Epoch 10/250\n",
      "187/187 [==============================] - 0s - loss: 1.3747 - acc: 0.2727     \n",
      "Epoch 11/250\n",
      "187/187 [==============================] - 0s - loss: 1.3740 - acc: 0.2727     \n",
      "Epoch 12/250\n",
      "187/187 [==============================] - 0s - loss: 1.3728 - acc: 0.2727     \n",
      "Epoch 13/250\n",
      "187/187 [==============================] - 0s - loss: 1.3722 - acc: 0.2727     \n",
      "Epoch 14/250\n",
      "187/187 [==============================] - 0s - loss: 1.3714 - acc: 0.2727     \n",
      "Epoch 15/250\n",
      "187/187 [==============================] - 0s - loss: 1.3703 - acc: 0.2727     \n",
      "Epoch 16/250\n",
      "187/187 [==============================] - 0s - loss: 1.3699 - acc: 0.2727     \n",
      "Epoch 17/250\n",
      "187/187 [==============================] - 0s - loss: 1.3692 - acc: 0.2727     \n",
      "Epoch 18/250\n",
      "187/187 [==============================] - 0s - loss: 1.3688 - acc: 0.2727     \n",
      "Epoch 19/250\n",
      "187/187 [==============================] - 0s - loss: 1.3680 - acc: 0.2727     \n",
      "Epoch 20/250\n",
      "187/187 [==============================] - 0s - loss: 1.3676 - acc: 0.2727     \n",
      "Epoch 21/250\n",
      "187/187 [==============================] - 0s - loss: 1.3671 - acc: 0.2727     \n",
      "Epoch 22/250\n",
      "187/187 [==============================] - 0s - loss: 1.3665 - acc: 0.2727     \n",
      "Epoch 23/250\n",
      "187/187 [==============================] - 0s - loss: 1.3660 - acc: 0.3476     \n",
      "Epoch 24/250\n",
      "187/187 [==============================] - 0s - loss: 1.3656 - acc: 0.3476     \n",
      "Epoch 25/250\n",
      "187/187 [==============================] - 0s - loss: 1.3653 - acc: 0.3636     \n",
      "Epoch 26/250\n",
      "187/187 [==============================] - 0s - loss: 1.3647 - acc: 0.3797     \n",
      "Epoch 27/250\n",
      "187/187 [==============================] - 0s - loss: 1.3645 - acc: 0.3797     \n",
      "Epoch 28/250\n",
      "187/187 [==============================] - 0s - loss: 1.3640 - acc: 0.3797     \n",
      "Epoch 29/250\n",
      "187/187 [==============================] - 0s - loss: 1.3635 - acc: 0.3904     \n",
      "Epoch 30/250\n",
      "187/187 [==============================] - 0s - loss: 1.3631 - acc: 0.3583     \n",
      "Epoch 31/250\n",
      "187/187 [==============================] - 0s - loss: 1.3627 - acc: 0.3583     \n",
      "Epoch 32/250\n",
      "187/187 [==============================] - 0s - loss: 1.3623 - acc: 0.3583     \n",
      "Epoch 33/250\n",
      "187/187 [==============================] - 0s - loss: 1.3618 - acc: 0.3583     \n",
      "Epoch 34/250\n",
      "187/187 [==============================] - 0s - loss: 1.3615 - acc: 0.3583     \n",
      "Epoch 35/250\n",
      "187/187 [==============================] - 0s - loss: 1.3609 - acc: 0.3583     \n",
      "Epoch 36/250\n",
      "187/187 [==============================] - 0s - loss: 1.3605 - acc: 0.3583     \n",
      "Epoch 37/250\n",
      "187/187 [==============================] - 0s - loss: 1.3600 - acc: 0.3583     \n",
      "Epoch 38/250\n",
      "187/187 [==============================] - 0s - loss: 1.3597 - acc: 0.3583     \n",
      "Epoch 39/250\n",
      "187/187 [==============================] - 0s - loss: 1.3587 - acc: 0.3583     \n",
      "Epoch 40/250\n",
      "187/187 [==============================] - 0s - loss: 1.3577 - acc: 0.3583     \n",
      "Epoch 41/250\n",
      "187/187 [==============================] - 0s - loss: 1.3564 - acc: 0.3583     \n",
      "Epoch 42/250\n",
      "187/187 [==============================] - 0s - loss: 1.3548 - acc: 0.3850     \n",
      "Epoch 43/250\n",
      "187/187 [==============================] - 0s - loss: 1.3532 - acc: 0.4118     \n",
      "Epoch 44/250\n",
      "187/187 [==============================] - 0s - loss: 1.3529 - acc: 0.3797     \n",
      "Epoch 45/250\n",
      "187/187 [==============================] - 0s - loss: 1.3522 - acc: 0.3797     \n",
      "Epoch 46/250\n",
      "187/187 [==============================] - 0s - loss: 1.3513 - acc: 0.3797     \n",
      "Epoch 47/250\n",
      "187/187 [==============================] - 0s - loss: 1.3506 - acc: 0.3797     \n",
      "Epoch 48/250\n",
      "187/187 [==============================] - 0s - loss: 1.3497 - acc: 0.3797     \n",
      "Epoch 49/250\n",
      "187/187 [==============================] - 0s - loss: 1.3489 - acc: 0.3797     \n",
      "Epoch 50/250\n",
      "187/187 [==============================] - 0s - loss: 1.3480 - acc: 0.3797     \n",
      "Epoch 51/250\n",
      "187/187 [==============================] - 0s - loss: 1.3472 - acc: 0.3797     \n",
      "Epoch 52/250\n",
      "187/187 [==============================] - 0s - loss: 1.3462 - acc: 0.3797     \n",
      "Epoch 53/250\n",
      "187/187 [==============================] - 0s - loss: 1.3454 - acc: 0.4118     \n",
      "Epoch 54/250\n",
      "187/187 [==============================] - 0s - loss: 1.3443 - acc: 0.4118     \n",
      "Epoch 55/250\n",
      "187/187 [==============================] - 0s - loss: 1.3433 - acc: 0.4118     \n",
      "Epoch 56/250\n",
      "187/187 [==============================] - 0s - loss: 1.3424 - acc: 0.4118     \n",
      "Epoch 57/250\n",
      "187/187 [==============================] - 0s - loss: 1.3413 - acc: 0.4118     \n",
      "Epoch 58/250\n",
      "187/187 [==============================] - 0s - loss: 1.3402 - acc: 0.4118     \n",
      "Epoch 59/250\n",
      "187/187 [==============================] - 0s - loss: 1.3391 - acc: 0.4118     \n",
      "Epoch 60/250\n",
      "187/187 [==============================] - 0s - loss: 1.3380 - acc: 0.4118     \n",
      "Epoch 61/250\n",
      "187/187 [==============================] - 0s - loss: 1.3370 - acc: 0.4118     \n",
      "Epoch 62/250\n",
      "187/187 [==============================] - 0s - loss: 1.3356 - acc: 0.4118     \n",
      "Epoch 63/250\n",
      "187/187 [==============================] - 0s - loss: 1.3345 - acc: 0.4118     \n",
      "Epoch 64/250\n",
      "187/187 [==============================] - 0s - loss: 1.3331 - acc: 0.4118     \n",
      "Epoch 65/250\n",
      "187/187 [==============================] - 0s - loss: 1.3317 - acc: 0.4118     \n",
      "Epoch 66/250\n",
      "187/187 [==============================] - 0s - loss: 1.3292 - acc: 0.4118     \n",
      "Epoch 67/250\n",
      "187/187 [==============================] - 0s - loss: 1.3273 - acc: 0.3797     \n",
      "Epoch 68/250\n",
      "187/187 [==============================] - 0s - loss: 1.3256 - acc: 0.3797     \n",
      "Epoch 69/250\n",
      "187/187 [==============================] - 0s - loss: 1.3241 - acc: 0.3797     \n",
      "Epoch 70/250\n",
      "187/187 [==============================] - 0s - loss: 1.3224 - acc: 0.3797     \n",
      "Epoch 71/250\n",
      "187/187 [==============================] - 0s - loss: 1.3203 - acc: 0.3797     \n",
      "Epoch 72/250\n",
      "187/187 [==============================] - 0s - loss: 1.3189 - acc: 0.4118     \n",
      "Epoch 73/250\n",
      "187/187 [==============================] - 0s - loss: 1.3168 - acc: 0.4118     \n",
      "Epoch 74/250\n",
      "187/187 [==============================] - 0s - loss: 1.3157 - acc: 0.4118     \n",
      "Epoch 75/250\n",
      "187/187 [==============================] - 0s - loss: 1.3129 - acc: 0.4118     \n",
      "Epoch 76/250\n",
      "187/187 [==============================] - 0s - loss: 1.3109 - acc: 0.4118     \n",
      "Epoch 77/250\n",
      "187/187 [==============================] - 0s - loss: 1.3087 - acc: 0.4118     \n",
      "Epoch 78/250\n",
      "187/187 [==============================] - 0s - loss: 1.3075 - acc: 0.4118     \n",
      "Epoch 79/250\n",
      "187/187 [==============================] - 0s - loss: 1.3054 - acc: 0.3957     \n",
      "Epoch 80/250\n",
      "187/187 [==============================] - 0s - loss: 1.3027 - acc: 0.3904     \n",
      "Epoch 81/250\n",
      "187/187 [==============================] - 0s - loss: 1.3002 - acc: 0.4118     \n",
      "Epoch 82/250\n",
      "187/187 [==============================] - 0s - loss: 1.2979 - acc: 0.4118     \n",
      "Epoch 83/250\n",
      "187/187 [==============================] - 0s - loss: 1.2962 - acc: 0.4118     \n",
      "Epoch 84/250\n",
      "187/187 [==============================] - 0s - loss: 1.2927 - acc: 0.4118     \n",
      "Epoch 85/250\n",
      "187/187 [==============================] - 0s - loss: 1.2903 - acc: 0.4278     \n",
      "Epoch 86/250\n",
      "187/187 [==============================] - 0s - loss: 1.2859 - acc: 0.4118     \n",
      "Epoch 87/250\n",
      "187/187 [==============================] - 0s - loss: 1.2808 - acc: 0.4118     \n",
      "Epoch 88/250\n",
      "187/187 [==============================] - 0s - loss: 1.2787 - acc: 0.3797     \n",
      "Epoch 89/250\n",
      "187/187 [==============================] - 0s - loss: 1.2722 - acc: 0.3797     \n",
      "Epoch 90/250\n",
      "187/187 [==============================] - 0s - loss: 1.2675 - acc: 0.4332     \n",
      "Epoch 91/250\n",
      "187/187 [==============================] - 0s - loss: 1.2630 - acc: 0.4599     \n",
      "Epoch 92/250\n",
      "187/187 [==============================] - 0s - loss: 1.2599 - acc: 0.4599     \n",
      "Epoch 93/250\n",
      "187/187 [==============================] - 0s - loss: 1.2546 - acc: 0.4118     \n",
      "Epoch 94/250\n",
      "187/187 [==============================] - 0s - loss: 1.2509 - acc: 0.4225     \n",
      "Epoch 95/250\n",
      "187/187 [==============================] - 0s - loss: 1.2461 - acc: 0.4599     \n",
      "Epoch 96/250\n",
      "187/187 [==============================] - 0s - loss: 1.2476 - acc: 0.4599     \n",
      "Epoch 97/250\n",
      "187/187 [==============================] - 0s - loss: 1.2408 - acc: 0.4492     \n",
      "Epoch 98/250\n",
      "187/187 [==============================] - 0s - loss: 1.2351 - acc: 0.4118     \n",
      "Epoch 99/250\n",
      "187/187 [==============================] - 0s - loss: 1.2310 - acc: 0.4599     \n",
      "Epoch 100/250\n",
      "187/187 [==============================] - 0s - loss: 1.2265 - acc: 0.4599     \n",
      "Epoch 101/250\n",
      "187/187 [==============================] - 0s - loss: 1.2213 - acc: 0.4599     \n",
      "Epoch 102/250\n",
      "187/187 [==============================] - 0s - loss: 1.2164 - acc: 0.4599     \n",
      "Epoch 103/250\n",
      "187/187 [==============================] - 0s - loss: 1.2123 - acc: 0.4599     \n",
      "Epoch 104/250\n",
      "187/187 [==============================] - 0s - loss: 1.2110 - acc: 0.4599     \n",
      "Epoch 105/250\n",
      "187/187 [==============================] - 0s - loss: 1.2064 - acc: 0.4599     \n",
      "Epoch 106/250\n",
      "187/187 [==============================] - 0s - loss: 1.1965 - acc: 0.4599     \n",
      "Epoch 107/250\n",
      "187/187 [==============================] - 0s - loss: 1.1913 - acc: 0.4599     \n",
      "Epoch 108/250\n",
      "187/187 [==============================] - 0s - loss: 1.1860 - acc: 0.4599     \n",
      "Epoch 109/250\n",
      "187/187 [==============================] - 0s - loss: 1.1801 - acc: 0.4599     \n",
      "Epoch 110/250\n",
      "187/187 [==============================] - 0s - loss: 1.1846 - acc: 0.4599     \n",
      "Epoch 111/250\n",
      "187/187 [==============================] - 0s - loss: 1.1729 - acc: 0.4759     \n",
      "Epoch 112/250\n",
      "187/187 [==============================] - 0s - loss: 1.1718 - acc: 0.5080     \n",
      "Epoch 113/250\n",
      "187/187 [==============================] - 0s - loss: 1.1733 - acc: 0.4439     \n",
      "Epoch 114/250\n",
      "187/187 [==============================] - 0s - loss: 1.1651 - acc: 0.4599     \n",
      "Epoch 115/250\n",
      "187/187 [==============================] - 0s - loss: 1.1606 - acc: 0.5080     \n",
      "Epoch 116/250\n",
      "187/187 [==============================] - 0s - loss: 1.1513 - acc: 0.4813     \n",
      "Epoch 117/250\n",
      "187/187 [==============================] - 0s - loss: 1.1561 - acc: 0.4599     \n",
      "Epoch 118/250\n",
      "187/187 [==============================] - 0s - loss: 1.1567 - acc: 0.4759     \n",
      "Epoch 119/250\n",
      "187/187 [==============================] - 0s - loss: 1.1523 - acc: 0.5080     \n",
      "Epoch 120/250\n",
      "187/187 [==============================] - 0s - loss: 1.1567 - acc: 0.4759     \n",
      "Epoch 121/250\n",
      "187/187 [==============================] - 0s - loss: 1.1443 - acc: 0.4599     \n",
      "Epoch 122/250\n",
      "187/187 [==============================] - 0s - loss: 1.1379 - acc: 0.5080     \n",
      "Epoch 123/250\n",
      "187/187 [==============================] - 0s - loss: 1.1416 - acc: 0.5080     \n",
      "Epoch 124/250\n",
      "187/187 [==============================] - 0s - loss: 1.1297 - acc: 0.4920     \n",
      "Epoch 125/250\n",
      "187/187 [==============================] - 0s - loss: 1.1291 - acc: 0.4599     \n",
      "Epoch 126/250\n",
      "187/187 [==============================] - 0s - loss: 1.1187 - acc: 0.4813     \n",
      "Epoch 127/250\n",
      "187/187 [==============================] - 0s - loss: 1.1203 - acc: 0.5080     \n",
      "Epoch 128/250\n",
      "187/187 [==============================] - 0s - loss: 1.1193 - acc: 0.4813     \n",
      "Epoch 129/250\n",
      "187/187 [==============================] - 0s - loss: 1.1129 - acc: 0.4599     \n",
      "Epoch 130/250\n",
      "187/187 [==============================] - 0s - loss: 1.1061 - acc: 0.5080     \n",
      "Epoch 131/250\n",
      "187/187 [==============================] - 0s - loss: 1.1064 - acc: 0.5080     \n",
      "Epoch 132/250\n",
      "187/187 [==============================] - 0s - loss: 1.1081 - acc: 0.4813     \n",
      "Epoch 133/250\n",
      "187/187 [==============================] - 0s - loss: 1.0985 - acc: 0.4706     \n",
      "Epoch 134/250\n",
      "187/187 [==============================] - 0s - loss: 1.0971 - acc: 0.5080     \n",
      "Epoch 135/250\n",
      "187/187 [==============================] - 0s - loss: 1.0939 - acc: 0.5080     \n",
      "Epoch 136/250\n",
      "187/187 [==============================] - 0s - loss: 1.0884 - acc: 0.4599     \n",
      "Epoch 137/250\n",
      "187/187 [==============================] - 0s - loss: 1.0821 - acc: 0.5080     \n",
      "Epoch 138/250\n",
      "187/187 [==============================] - 0s - loss: 1.0825 - acc: 0.5080     \n",
      "Epoch 139/250\n",
      "187/187 [==============================] - 0s - loss: 1.0738 - acc: 0.5080     \n",
      "Epoch 140/250\n",
      "187/187 [==============================] - 0s - loss: 1.0737 - acc: 0.4759     \n",
      "Epoch 141/250\n",
      "187/187 [==============================] - 0s - loss: 1.0666 - acc: 0.5080     \n",
      "Epoch 142/250\n",
      "187/187 [==============================] - 0s - loss: 1.0643 - acc: 0.5080     \n",
      "Epoch 143/250\n",
      "187/187 [==============================] - 0s - loss: 1.0584 - acc: 0.5080     \n",
      "Epoch 144/250\n",
      "187/187 [==============================] - 0s - loss: 1.0566 - acc: 0.5080     \n",
      "Epoch 145/250\n",
      "187/187 [==============================] - 0s - loss: 1.0494 - acc: 0.5080     \n",
      "Epoch 146/250\n",
      "187/187 [==============================] - 0s - loss: 1.0519 - acc: 0.5080     \n",
      "Epoch 147/250\n",
      "187/187 [==============================] - 0s - loss: 1.0413 - acc: 0.5080     \n",
      "Epoch 148/250\n",
      "187/187 [==============================] - 0s - loss: 1.0425 - acc: 0.5080     \n",
      "Epoch 149/250\n",
      "187/187 [==============================] - 0s - loss: 1.0402 - acc: 0.5080     \n",
      "Epoch 150/250\n",
      "187/187 [==============================] - 0s - loss: 1.0310 - acc: 0.5080     \n",
      "Epoch 151/250\n",
      "187/187 [==============================] - 0s - loss: 1.0391 - acc: 0.4599     \n",
      "Epoch 152/250\n",
      "187/187 [==============================] - 0s - loss: 1.0268 - acc: 0.5080     \n",
      "Epoch 153/250\n",
      "187/187 [==============================] - 0s - loss: 1.0238 - acc: 0.5080     \n",
      "Epoch 154/250\n",
      "187/187 [==============================] - 0s - loss: 1.0226 - acc: 0.5080     \n",
      "Epoch 155/250\n",
      "187/187 [==============================] - 0s - loss: 1.0200 - acc: 0.5080     \n",
      "Epoch 156/250\n",
      "187/187 [==============================] - 0s - loss: 1.0158 - acc: 0.5080     \n",
      "Epoch 157/250\n",
      "187/187 [==============================] - 0s - loss: 1.0116 - acc: 0.5080     \n",
      "Epoch 158/250\n",
      "187/187 [==============================] - 0s - loss: 1.0129 - acc: 0.5080     \n",
      "Epoch 159/250\n",
      "187/187 [==============================] - 0s - loss: 1.0087 - acc: 0.5134     \n",
      "Epoch 160/250\n",
      "187/187 [==============================] - 0s - loss: 1.0032 - acc: 0.5080     \n",
      "Epoch 161/250\n",
      "187/187 [==============================] - 0s - loss: 1.0078 - acc: 0.5080     \n",
      "Epoch 162/250\n",
      "187/187 [==============================] - 0s - loss: 1.0058 - acc: 0.5134     \n",
      "Epoch 163/250\n",
      "187/187 [==============================] - 0s - loss: 0.9963 - acc: 0.4973     \n",
      "Epoch 164/250\n",
      "187/187 [==============================] - 0s - loss: 1.0051 - acc: 0.5348     \n",
      "Epoch 165/250\n",
      "187/187 [==============================] - 0s - loss: 0.9898 - acc: 0.5027     \n",
      "Epoch 166/250\n",
      "187/187 [==============================] - 0s - loss: 1.0053 - acc: 0.4973     \n",
      "Epoch 167/250\n",
      "187/187 [==============================] - 0s - loss: 0.9872 - acc: 0.5080     \n",
      "Epoch 168/250\n",
      "187/187 [==============================] - 0s - loss: 0.9899 - acc: 0.5294     \n",
      "Epoch 169/250\n",
      "187/187 [==============================] - 0s - loss: 0.9905 - acc: 0.4973     \n",
      "Epoch 170/250\n",
      "187/187 [==============================] - 0s - loss: 0.9887 - acc: 0.4973     \n",
      "Epoch 171/250\n",
      "187/187 [==============================] - 0s - loss: 0.9849 - acc: 0.5294     \n",
      "Epoch 172/250\n",
      "187/187 [==============================] - 0s - loss: 0.9789 - acc: 0.4973     \n",
      "Epoch 173/250\n",
      "187/187 [==============================] - 0s - loss: 0.9768 - acc: 0.4973     \n",
      "Epoch 174/250\n",
      "187/187 [==============================] - 0s - loss: 0.9787 - acc: 0.5134     \n",
      "Epoch 175/250\n",
      "187/187 [==============================] - 0s - loss: 0.9748 - acc: 0.4973     \n",
      "Epoch 176/250\n",
      "187/187 [==============================] - 0s - loss: 0.9739 - acc: 0.4973     \n",
      "Epoch 177/250\n",
      "187/187 [==============================] - 0s - loss: 0.9729 - acc: 0.5401     \n",
      "Epoch 178/250\n",
      "187/187 [==============================] - 0s - loss: 0.9740 - acc: 0.4973     \n",
      "Epoch 179/250\n",
      "187/187 [==============================] - 0s - loss: 0.9668 - acc: 0.4973     \n",
      "Epoch 180/250\n",
      "187/187 [==============================] - 0s - loss: 0.9695 - acc: 0.5508     \n",
      "Epoch 181/250\n",
      "187/187 [==============================] - 0s - loss: 0.9614 - acc: 0.4973     \n",
      "Epoch 182/250\n",
      "187/187 [==============================] - 0s - loss: 0.9691 - acc: 0.4973     \n",
      "Epoch 183/250\n",
      "187/187 [==============================] - 0s - loss: 0.9566 - acc: 0.4973     \n",
      "Epoch 184/250\n",
      "187/187 [==============================] - 0s - loss: 0.9661 - acc: 0.5508     \n",
      "Epoch 185/250\n",
      "187/187 [==============================] - 0s - loss: 0.9623 - acc: 0.4973     \n",
      "Epoch 186/250\n",
      "187/187 [==============================] - 0s - loss: 0.9613 - acc: 0.4973     \n",
      "Epoch 187/250\n",
      "187/187 [==============================] - 0s - loss: 0.9573 - acc: 0.5401     \n",
      "Epoch 188/250\n",
      "187/187 [==============================] - 0s - loss: 0.9524 - acc: 0.5241     \n",
      "Epoch 189/250\n",
      "187/187 [==============================] - 0s - loss: 0.9549 - acc: 0.4973     \n",
      "Epoch 190/250\n",
      "187/187 [==============================] - 0s - loss: 0.9534 - acc: 0.5134     \n",
      "Epoch 191/250\n",
      "187/187 [==============================] - 0s - loss: 0.9548 - acc: 0.5187     \n",
      "Epoch 192/250\n",
      "187/187 [==============================] - 0s - loss: 0.9482 - acc: 0.4973     \n",
      "Epoch 193/250\n",
      "187/187 [==============================] - 0s - loss: 0.9490 - acc: 0.5294     \n",
      "Epoch 194/250\n",
      "187/187 [==============================] - 0s - loss: 0.9478 - acc: 0.5241     \n",
      "Epoch 195/250\n",
      "187/187 [==============================] - 0s - loss: 0.9426 - acc: 0.4973     \n",
      "Epoch 196/250\n",
      "100/187 [===============>..............] - ETA: 0s - loss: 0.9010 - acc: 0.5700"
     ]
    }
   ],
   "source": [
    "train_and_eval(\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
